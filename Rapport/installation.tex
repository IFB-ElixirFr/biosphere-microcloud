\chapter {Installation et déploiement des VM}

\section {Description des VM}

Il y 6 machines virtuelles (VM) au total dont 5 conçues depuis Nuvla et 1 machine OpenStack déployée sur le cloud prabi-girofle.
Le code des VM est dans le dépôt biosphere-microcloud (\url{https://github.com/IFB-ElixirFr/biosphere-microcloud/}); il y a un dossier par VM:

\begin{itemize}
	\item frontend voir section \ref{frontend}
	\item mysql voir section \ref{mysql}
	\item VM permanente voir section \ref{VMpermanente}
	\item master et slave voir section \ref{master&slave}
	\item nfsserver voir section \ref{nfsserver}
\end{itemize}

Il y a 2 serveurs de bases de données dans MicroCloud. Un serveur MySQL installé via Docker dans la VM MySQL et un serveur MySQL sur la VM permanente.
Pour se connecter aux VM voir la doc : \url{https://intranet.genoscope.cns.fr/agc/redmine/projects/microcloud/wiki/Connexion_aux_VM}

\subsection {VM frontend}\label{frontend}

La VM frontend permet de déployer la partie web de la plateforme MicroScope.
L'image de base est une image CentOS 7.

Le code est dans le dossier frontend; voir \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/tree/master/frontend/}.
Le composant slipstream est dans le dossier frontend; voir \url{https://nuv.la/module/ifb/devzone/MicroCloud/frontend/}.
\bigskip

Lors du déploiement de la VM le code web copié dans le répertoire \textbf{/var/www/html/} de la VM.
L'URL de la plateforme est : \textbf{\$IP\_frontend/home/index.php}.

La VM frontend possède un client mariaDB (et non pas MySQL du fait de conflits existants entre le dépôt remi-php71 installé et le dépôt IUS qui fournit le client MySQL).\newline

Pour se connecter en ssh à la VM frontend : 
\begin{lstlisting}[style=Bash]
$ ssh centos@${IP_frontend}
\end{lstlisting}

\begin{mycolorbox}Si le message d’erreur \textbf{256} s’affiche, cela signifie simplement qu’il n’y a pas d’organisme en base. De ce fait, la plupart des onglets sont inaccessibles ainsi que le formulaire d’authentification.
\end{mycolorbox}

\subsection {VM mysql}\label{mysql}

Le code est dans le dossier mysql voir \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/tree/master/mysql/}.
Le composant slipstream est dans le dossier mysql voir \url{https://nuv.la/module/ifb/devzone/MicroCloud/mysql/}.

L'image de base est une image CentOS 7. La VM mysql possède un serveur MySQL installé via Docker sur lequel on retrouve les bases de données pkgdb, GO\_CPD, GO\_Conf, GO\_RES, PUB\_CPD, REFSEQDB, JBPMmicroscope et PRESTATIONDB.
\newline
Les tables nécessaires à l'installation de MicroScope sont également listées dans le wiki : \url{https://intranet.genoscope.cns.fr/agc/redmine/projects/microcloud/wiki/Tables_necessaires_a_installation}.
\newline

Pour se connecter à la VM mysql, il faut passer par le frontend :
\begin{lstlisting}[style=bash]
$ ssh -A centos@${IP_mysql} -J centos@${IP_frontend}
\end{lstlisting}
\bigskip

Si le serveur ne répond pas, il faut aller voir si le docker n'a pas planté (cela arrive pour des requêtes SQL trop gourmandes en RAM).
Pour relancer le docker :
\begin{lstlisting}[style=bash]
$ sudo su
$ docker ps -a
$ docker start ${ID_container}
\end{lstlisting}

\subsection {VM permanente}\label{VMpermanente}

C'est une VM OpenStack (\textbf{umr5558-microcloud.univ-lyon1.fr}) du cloud \cloudInstance{ifb-prabi-girofle} disposant de 200 Go de stockage et 8 Go de RAM (elle est actuellement sous-dimensionnée par rapport à nos besoins). La machine a été installée avec Sylvain Bonneval. L'image de base est une image Debian 9.8.

La machine permanente n'est accessible depuis l'extérieur qu'en SSH donc nous ne pouvons pas y accéder en MySQL (port 3306) depuis un autre cloud.
\newline

La procédure d'installation est dans le fichier \textbf{Installation.md} du répertoire \textbf{/root}. La VM permanente sert au stockage des données des banques. Nous avons utilisé \textbf{rsync} pour l'import des données dans le serveur MySQL.
\newline

Logiciels installés : serveur MySQL, rsync, phpMyAdmin (installé mais non configuré). 
\newline

A terme, il serait utile d'avoir un système de gestion des banques tel que BioMAJ \url{https://biomaj.genouest.org/} installé sur cette machine.

Pour se connecter : 
\begin{lstlisting}[style=bash]
$ ssh root@134.214.33.214
\end{lstlisting}
\bigskip

Sur le serveur MySQL, il y a les schémas des bases DB et une partie des données de la base pour les tests (nous avons testés les onglets \textbf{Genome Browser}, \textbf{Identical Gene Names}) :
\begin{itemize}
	\item les bases ANTISMASHDB, CARDDB, COGDB, EGGNOGDB, ENZYMEDB, ESSDB, FIGFAMDB, INTERPRODATADB, KEGGDB, RHEADB, TAXONOMYDB, TIGRFAMDB, UNIFIREDB, UNIPROTKBDB, VIRULENCEDB, microcyc, DBWorkflow
	\item les données (en partie) de la base UNIPROTKBDB pour les tests
	\item les données de DBWORKFLOW
	\item les données de l'organisme \textit{Acinetobacter} dans la base TAXONOMYDB (taxon id 202950)
\end{itemize}

Le script \script{microscopeDBschema.py} du module MicroCloud a été utilisé pour créer les schémas.
\newline

Pour se connecter au serveur MySQL :
\begin{lstlisting}[style=bash]
$ mysql -p{MOT_DE_PASSE_SERVEUR_MYSQL_VM_PERMANENTE}
\end{lstlisting}

Les mots de passe (serveur MySQL et phpMyAdmin) sont stockés dans le répertoire \textbf{/root} de la VM.
\newline 

Pour copier les données, mieux vaut utiliser rsync et copier les données dans le répertoire \textbf{/var/lib/mysql-files/} de la VM permanente avant insertion en base.

\begin{lstlisting}[style=bash]
$ LOAD DATA INFILE '/var/lib/mysql-files/$file.DB' INTO TABLE $table;
\end{lstlisting}

\subsection{VM master et VM slave(s)} \label{master&slave}

Le code d’installation de ces VM est dans le dépôt de biosphere-commons : \url{https://github.com/IFB-ElixirFr/biosphere-commons}.
L'image de base est une image Ubuntu 18. Le code slipstream est basé sur les travaux de Jonathan Lorenzo et Bryan Brancotte. 

Les composants slurm master et slave ont été copiés depuis l'appliance Slurm\_Cluster\_ubuntu18 voir \url{https://nuv.la/module/ifb/devzone/jlorenzo/cluster/Slurm_Cluster_ubuntu18}.

Concernant la VM master, le code est dans le dossier master; voir
\url{https://github.com/IFB-ElixirFr/biosphere-microcloud/tree/master/master/}.
Le code du composant slipstream est dans le dossier master voir; \url{https://nuv.la/module/ifb/devzone/MicroCloud/master/}.

Pour la VM slave, voir les dossiers correspondants.\newline

Nous avons installé le moteur de workflow jBPM couplé avec un cluster slurm sur la VM master. L'ordonnancement des wokflows est ensuite géré à l'aide du cluster slurm. La VM master étant considérée comme la machine maître et les VM slaves comme noeuds de calcul.

Le serveur d'application Tomcat est installé (version tomcat-9.0.31 : \url{http://mirrors.ircam.fr/pub/apache/tomcat/tomcat-9/v9.0.31/bin/apache-tomcat-9.0.31.tar.gz}).
Il est utilisé comme serveur par jBPM (pour accéder à Tomcat : http://\$IP\_master).

Nous avons également eu besoin d'installer Pegasus-mpi-cluster (version 4.9.2 : \url{https://github.com/pegasus-isi/pegasus/archive/4.9.2.zip}) en complément de jBPM. Lors de l'installation de pegasus-mpi-cluster, la librairie libnuma a posé problème mais celle-ci n'est pas nécessaire pour les architectures non NUMA (voir \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/blob/master/master/04_deployment.sh}).

Le lancement des workflows se fait à l'aide du module bagsub lui-même lancé par jBPM. Nous avons fait quelques modifications du module bagsub afin qu'il puisse être utilisé dans la VM master.
Le script \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/blob/master/master/import_modules.sh} modifie le module bagsub, en supprimant l'option ulimit qui ne fonctionne pas en Dash, et, en ajoutant le paramètre MCA btl\_tcp\_if\_exclude pour exclure les interfaces réseaux docker0 et lo qui peuvent engendrer des conflits lors du lancement de jobs slurm.

\section{Lien federated entre la VM mysql et  la VM permanente}
Les bases DB des banques sont accessibles depuis la VM mysql via des liens federated \url{https://dev.mysql.com/doc/refman/8.0/en/federated-storage-engine.html}( 
voir \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/blob/master/frontend/create_federated_links.sh}).
\bigskip

\begin{mycolorbox}
	Lorsque les schémas des bases DB de la VM permanente sont mis-à-jour, il faut penser à redéployer MicroCloud afin de mettre à jour les liens federated.
\end{mycolorbox}

\section{Partage NFS entre les différentes VM}

\label{nfsserver} Le composant nfsserver a été créé en s'inspirant du travail de Stéphane Delmotte.
Il permet de fournir un serveur partagé entre les différentes VM.
L'image de base est une image CentOS 7.
Le code est dans le dossier nfsserver voir  \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/tree/master/nfsserver/}.
Le composant slipstream est dans le dossier nfsserver voir
\url{https://nuv.la/module/ifb/devzone/MicroCloud/nfsserver/}.

Le répertoire partagé \textbf{/var/nfsshare} du serveur NFS est monté dans le répertoire \textbf{/env}
des VM frontend, backend, master et slave(s).
Le répertoire \textbf{/env} se veut similaire au répertoire de même nom sur l’etna0. 
Les fonctions permettant la création du répertoire partagé sont dans le fichier \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/blob/master/lib.sh}.

\section{VM master}

\subsection{Importation des modules}
En premier lieu, faire la liste de tous les modules nécessaires à la création de la nouvelle instance MicroCloud.
Puis, utiliser le script \script{createModulesTarball.py} du module MicroCloud.

Mise à jour de l'environnement des modules :
actuellement l'environnement de MicroCloud ne permet d'utiliser que les modules \textbf{bagsub-2.4.3}, \textbf{AGCScriptToolMic-2.0}, \textbf{micGenome-7.0.0}, \textbf{micJBPMwrapper-3.10.8}, \textbf{micPrestation-2.0} et \textbf{micDirecton-1.0}.
\newline

\begin{mycolorbox}
	Pour tout ajout de nouveaux modules, il faut mettre à jour le fichier \path{microcloud.profile} et créer les répertoires nécessaires (voir \url{https://github.com/IFB-ElixirFr/biosphere-microcloud/blob/master/master/04_deployment.sh}).
\end{mycolorbox}

Puis sourcer le fichier \path{microcloud.profile} dans la VM master :
\begin{lstlisting}[style=bash]
$ source /env/cns/proj/agc/module/profiles/microcloud.profile
\end{lstlisting}

